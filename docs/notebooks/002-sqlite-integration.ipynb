{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite itegration\n",
    "\n",
    "If you want to process your sensor data and store it for later, you can use the sqlite integration. Gensor's `Timeseries` and `Dataset` come with a `.to_sql()` method which is uses `pandas.Series.to_sql()` method under the hood to save the data in a SQLite database. \n",
    "\n",
    "It is a simple implementation, where each timeseries is stored in a separate schema (database table) which is named in the following pattern: `f\"{location}_{sensor}_{variable}_{unit}\".lower()`. There is a double check on duplicates. First, when you create a `Dataset`, duplicates are nicely handled by merging timeseries from the same location, sensor and of the same variable and unit. Secondly the `Timeseries.to_sql()` method is designed to ignore conflicts, so only new records are inserted into the database if you attempt to run the same commend twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensor as gs\n",
    "from gensor.testdata import all_paths, pb02a_plain\n",
    "\n",
    "from gensor import read_from_csv\n",
    "\n",
    "pattern = r'[A-Za-z]{2}\\d{2}[A-Za-z]{1}|Barodiver'\n",
    "\n",
    "ds = read_from_csv(path=all_paths, \n",
    "                    file_format='vanessen', \n",
    "                    location_pattern=pattern)\n",
    "\n",
    "\n",
    "ds2 = read_from_csv(path=pb02a_plain, \n",
    "                    file_format='plain', \n",
    "                    location='PB02A',\n",
    "                    sensor='AV336')\n",
    "\n",
    "ds.add(ds2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `DatabaseConnection`\n",
    "\n",
    "Both saving and loading data from sqlite require a `DatabaseConnection` object to be passed as attribute. You can just instanciate it with empty parentheses to create a new database in the current working directory, or specify the path and name of the database.\n",
    "\n",
    "If you have an existing Gensor database, you can use `DatabaseConnection.get_tables()` to see if there already are some tables in the database that you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = gs.db.DatabaseConnection()\n",
    "db.get_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset to the database is straightforward. You just need to call `.to_sql()` on the dataset instance and check the tables again to see that now there are a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_sql(db)\n",
    "db.get_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensor import read_from_sql, Dataset\n",
    "\n",
    "# Issue: the unit name is case sensitive (shouldn't be)\n",
    "new_ds: Dataset = read_from_sql(db, True)\n",
    "new_ds.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
